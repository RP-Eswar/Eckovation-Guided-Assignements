{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "     \n",
    "    \n",
    "  Implement a face tracking algorithm using haar cascade algorithm and opencv. Using haar\n",
    "cascade, first implement a face detection algorithm that counts the total number of faces\n",
    "present in any given frame. Write the total number of faces detected on the top left of the\n",
    "image. Further modify the code to track the face if only one face is detected. Make sure that\n",
    "you draw the bounding box corresponding to all video frames. Note: you may need to fine\n",
    "tune the parameters for Haar Cascade Classifier to get optimal results and remove false\n",
    "positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Face detection is a computer technology being used in a variety of applications that\n",
    "identifies human faces in digital images. Face detection can be regarded as a specific case of\n",
    "object-class detection, which focuses on the detection of frontal human faces. Because faces\n",
    "are so complicated, there isnâ€™t a straightforward test that will tell if we found a face or not.\n",
    "Instead, thousands of small patterns and features must be matched for accurate facial detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    count = 0\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        count = count+1\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Display\n",
    "    count = str(count)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (00, 185)\n",
    "    fontScale = 1\n",
    "    color = (0, 0, 255)\n",
    "  \n",
    "    # Line thickness of 2 px\n",
    "    thickness = 1\n",
    "    cv2.putText(img , count, org, font, fontScale,\n",
    "                  color, thickness, cv2.LINE_AA, False)\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "# Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
